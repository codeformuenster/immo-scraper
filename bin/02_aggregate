#!/usr/bin/env python
""" Aggregate previously scraped data. """
import itertools
import json
from pathlib import Path

import pandas as pd

from immo_scraper.io.paths import AGGREGATED_CSV, ALERTS_IDS, AGGREGATED_CSV

# read raw data
filenames = [str(key) for key in BUCKET_NESTORIA.glob("*")]

filedata = []
for filename in filenames:
    print(f"Reading file {filename}...")
    with open(filename, "r") as f:
        filedata.append(json.loads(f.read()))

# format data
entries_dicts = list(itertools.chain(*filedata))
df = pd.DataFrame(entries_dicts).drop_duplicates()  # filter out duplicates

# ENGINEER FEATURES
# id of entry
df["id"] = df.apply(lambda row: row.lister_url.split("/")[4], axis=1)
# geo-coordinates
df["lat_long"] = df.apply(
    lambda row: f"{row.latitude: .3f} {row.longitude: .3f}", axis=1
)

# write result to bucket
df.to_csv(str(AGGREGATED_CSV))
