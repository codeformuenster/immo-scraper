#!/usr/bin/env python
""" Aggregate previously scraped data. """
import itertools
import json
from pathlib import Path

import pandas as pd

# paths
BUCKET_NESTORIA = Path("bucket/nestoria/")
BUCKET_AGGREGATED = Path("bucket/processed/aggregated.csv")

# read all scraped data from bucket
filenames = [str(key) for key in BUCKET_NESTORIA.glob("*")]
filedata = [json.loads(open(filename, "r").read()) for filename in filenames]

entries_dicts = list(itertools.chain(*filedata))

df = pd.DataFrame(entries_dicts).drop_duplicates()  # filter out duplicates

# FEATURES
# geo-coordinates
df["long_lat"] = df.apply(
    lambda row: f"{row.latitude: .3f} {row.longitude: .3f}", axis=1
)

# write result to bucket
df.to_csv(str(BUCKET_AGGREGATED))
