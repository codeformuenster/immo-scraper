#!/usr/bin/env python
import logging
import sys

import pandas as pd

from immo_scraper.alert import email
from immo_scraper.alert.io import get_ids_previous_alerts, log_alert
from immo_scraper import paths

logging.basicConfig(stream=sys.stdout, level=logging.INFO)

# read aggregated data from bucket
df_entries = pd.read_csv(str(paths.AGGREGATED_CSV), dtype={"id": str})

# check for new entries that are relevant to search criteria
df_relevant = (
    df_entries.query("bedroom_number >= 5")
    .query("price <= 400000")
    .query("size >= 100")
    .query("latitude < 52")
)

# select entries for which alerts are due
alerts_log = get_ids_previous_alerts()
df_alert = df_relevant[~df_relevant.id.isin(alerts_log)]

# If alerts are due: send email, log IDs
if len(df_alert) > 0:
    logging.info("New alerts are due.")
    msg_html = email.compose_html(df_alert)
    email.send(msg_html)
    # remember IDs for which alerted
    for id in df_alert.id:
        log_alert(id)
else:
    logging.info("No alerts due.")
